# -*- coding: utf-8 -*-
"""Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bHFOnnmt2u1G2B-d_BCTOCAuAJtVGx8a
"""

import pandas as pd

# Load the CSV file into a DataFrame
df1 = pd.read_csv("/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv")
df2 = pd.read_csv("/content/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv")
df3 = pd.read_csv("/content/Friday-WorkingHours-Morning.pcap_ISCX.csv")
df4 = pd.read_csv("/content/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv")
df5 = pd.read_csv("/content/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv")
df6 = pd.read_csv("/content/Monday-WorkingHours.pcap_ISCX.csv")
df7 = pd.read_csv("/content/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv")
df8 = pd.read_csv("/content/Tuesday-WorkingHours.pcap_ISCX.csv")

datasets = [df1,df2,df3,df4,df5,df6,df7,df8]

print("Different type of Attacks on Server")
for index, dataset in enumerate(datasets):
    print(f"{index}: {dataset[' Label'].unique()}")

df=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8],join="inner")

df.shape

df.info()

df.head()

# Get statistical summary of numerical features
display(df.describe().T)

# Get summary of categorical columns
display(df.describe(include=['object']).T)

missing_values = df.isnull().sum()

missing_values

df.columns

df.columns = df.columns.str.strip()
df["Label"].unique()
print(df['Label'].value_counts())

#GRAPH TO SHOW DISTRIBUTION OF ATTACK TRPE
# Ensure no NaN values in 'Label' column
import seaborn as sns
import matplotlib.pyplot as plt
df = df.dropna(subset=['Label'])

# Strip spaces to avoid duplicate labels
df['Label'] = df['Label'].str.strip()

# Get sorted label order
label_order = df['Label'].value_counts().index.to_list()

# Adjust figure size
plt.figure(figsize=(12, 6))

# Plot count of each label category
ax = sns.countplot(data=df, x="Label", palette="coolwarm", order=label_order)

for p in ax.patches:
    ax.annotate(f'{int(p.get_height())}',  # Convert float counts to integer
                (p.get_x() + p.get_width() / 2, p.get_height()),
                ha='center', va='bottom', fontsize=12, fontweight='bold')
plt.xticks(rotation=45, ha='right')

plt.xlabel("Attack Type", fontsize=12)
plt.ylabel("Number of Rows", fontsize=12)
plt.title("Distribution of Attack Types in the Dataset", fontsize=14)

plt.show()

# Identify columns where all values are 0
zero_columns = [col for col in df.columns if (df[col] == 0).all()]

# Print and store the list of columns with all zero values
print("Columns with all zero values:", zero_columns)

# Drop columns with all zero values
df = df.drop(columns=zero_columns)

print("Updated dataframe shape:", df.shape)

from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.feature_selection import RFE
from sklearn.preprocessing import LabelEncoder

# Encode categorical target variable if necessary
if df['Label'].dtype == 'object':
    label_encoder = LabelEncoder()
    df['Label'] = label_encoder.fit_transform(df['Label'])

# Separate features and target variable
X = df.drop(columns=['Label'])  # Features
y = df['Label']  # Target

# 1. **Correlation Analysis**
plt.figure(figsize=(12, 8))
correlation_matrix = X.corr()
sns.heatmap(correlation_matrix, cmap="coolwarm", linewidths=0.5)
plt.title("Feature Correlation Heatmap")
plt.show()

# Identify highly correlated features (correlation > 0.9)
corr_threshold = 0.9
high_corr_features = set()
cor_matrix = X.corr()

for i in range(len(cor_matrix.columns)):
    for j in range(i):
        if abs(cor_matrix.iloc[i, j]) > corr_threshold:
            colname = cor_matrix.columns[i]
            high_corr_features.add(colname)

print("Highly correlated features to consider removing:", high_corr_features)

"""Preprocessing (normalization and padding values)"""

# Min-max normalization
numeric_features = df.dtypes[df.dtypes != 'object'].index
df[numeric_features] = df[numeric_features].apply(
    lambda x: (x - x.min()) / (x.max() - x.min()))

# Fill empty values with the median of each column
df = df.fillna(df.median())

"""Split data"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
labelencoder = LabelEncoder()
df.iloc[:, -1] = labelencoder.fit_transform(df.iloc[:, -1])
X = df.drop(['Label'],axis=1).values
y = df.iloc[:, -1].values.reshape(-1,1)
y=np.ravel(y)
y = y.astype('int')
X_train, X_test, y_train, y_test = train_test_split(X,y, train_size = 0.7, test_size = 0.3, random_state = 0,stratify = y)

pd.Series(y_train).value_counts()

import time
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support


group1_models = {
    "SVM": LinearSVC(max_iter=1000, random_state=42, dual=False)  # dual=False is usually faster for n_samples > n_features
}

# Train, evaluate, and save model
for name, model in group1_models.items():
    print(f"\nüîπ Training {name}...")

    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Save trained model
    with open(f"{name}_model.pkl", "wb") as f:
        pickle.dump(model, f)

    # Predictions
    y_predict = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_predict)
    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_predict, average='weighted')

    # Print performance metrics
    print(f"‚úÖ {name} Accuracy: {accuracy:.4f}")
    print(f"üéØ Precision: {precision:.4f}")
    print(f"üîÑ Recall: {recall:.4f}")
    print(f"‚ö° F1-score: {fscore:.4f}")
    print(f"‚è≥ Training time: {training_time:.2f} s")

    # Print classification report
    print(classification_report(y_test, y_predict))

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_predict)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", linewidths=0.5, linecolor="black")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

import time
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression


group2_models = {
    "Na√Øve Bayes": GaussianNB(),
    "Logistic Regression": LogisticRegression(max_iter=500),
}

# Train, evaluate, and save models
for name, model in group2_models.items():
    print(f"\nüîπ Training {name}...")

    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Save trained model
    with open(f"{name}_model.pkl", "wb") as f:
        pickle.dump(model, f)

    # Predictions
    y_predict = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_predict)
    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_predict, average='weighted')

    # Print performance metrics
    print(f"‚úÖ {name} Accuracy: {accuracy:.4f}")
    print(f"üéØ Precision: {precision:.4f}")
    print(f"üîÑ Recall: {recall:.4f}")
    print(f"‚ö° F1-score: {fscore:.4f}")
    print(f"‚è≥ Training time: {training_time:.2f} s")

    # Print classification report
    print(classification_report(y_test, y_predict))

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_predict)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", linewidths=0.5, linecolor="black")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

import time
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


group1_models = {
    "Decision Tree": DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=5),
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
}

# Train, evaluate, and save models
for name, model in group1_models.items():
    print(f"\nüîπ Training {name}...")

    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Save trained model
    with open(f"{name}_model.pkl", "wb") as f:
        pickle.dump(model, f)

    # Predictions
    y_predict = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_predict)
    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_predict, average='weighted')

    # Print performance metrics
    print(f"‚úÖ {name} Accuracy: {accuracy:.4f}")
    print(f"üéØ Precision: {precision:.4f}")
    print(f"üîÑ Recall: {recall:.4f}")
    print(f"‚ö° F1-score: {fscore:.4f}")
    print(f"‚è≥ Training time: {training_time:.2f} s")

    # Print classification report
    print(classification_report(y_test, y_predict))

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_predict)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", linewidths=0.5, linecolor="black")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()

import time
import pickle
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support
from sklearn.neural_network import MLPClassifier


group3_models = {
    "ANN": MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=500, random_state=42)
}

# Train, evaluate, and save model
for name, model in group3_models.items():
    print(f"\nüîπ Training {name}...")

    start_time = time.time()
    model.fit(X_train, y_train)
    training_time = time.time() - start_time

    # Save trained model
    with open(f"{name}_model.pkl", "wb") as f:
        pickle.dump(model, f)

    # Predictions
    y_predict = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_predict)
    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_predict, average='weighted')

    # Print performance metrics
    print(f"‚úÖ {name} Accuracy: {accuracy:.4f}")
    print(f"üéØ Precision: {precision:.4f}")
    print(f"üîÑ Recall: {recall:.4f}")
    print(f"‚ö° F1-score: {fscore:.4f}")
    print(f"‚è≥ Training time: {training_time:.2f} s")

    # Print classification report
    print(classification_report(y_test, y_predict))

    # Plot confusion matrix
    cm = confusion_matrix(y_test, y_predict)
    plt.figure(figsize=(5, 5))
    sns.heatmap(cm, annot=True, cmap="Blues", fmt=".0f", linewidths=0.5, linecolor="black")
    plt.title(f"{name} Confusion Matrix")
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()